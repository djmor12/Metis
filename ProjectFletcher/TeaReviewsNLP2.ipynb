{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:14.596618Z",
     "start_time": "2018-06-01T21:45:14.458665Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importing the packages needed for this analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "plt.rcParams['figure.dpi']= 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:14.883115Z",
     "start_time": "2018-06-01T21:45:14.866833Z"
    }
   },
   "outputs": [],
   "source": [
    "#hard coding hybrid recommendation element\n",
    "tastingflavors = {'Spicy':['cocoa','clove', 'vanilla','pepper', 'saffron','nutmeg','licorice','menthol','cinnamon'],\\\n",
    "'Char':['ash','tar','toast','wood smoke','tobacco','fireplace','burnt food','grilled food'],\\\n",
    "'Sweet':['malt','brown sugar','candy','honey','caramel','molasses','burnt sugar','maple syrup','sweet'],\\\n",
    "'Nutty':['almond', 'peanut','walnut','chestnut','hazelnut', 'roasted nuts'],\\\n",
    "'Floral':['rose','hops','orchid','violet','jasmine','perfume','geranium','dandelion','honeysuckle','lily of the valley','orange blossom'],\\\n",
    "'Herbs':['thyme','parsley','cardamom','eucalyptus','fennel seed','coriander'],\\\n",
    "'Vegetables':['spinach','broccoli','zucchini','asparagus','garden peas','green pepper','squash blossom'],\\\n",
    "'Grass':['stems','straw','barnyard','grapeseed','fresh cut grass','grass'],\\\n",
    "'Wood':['evergreen','bark','cedar','resin','freshly cut wood','sawdust','wet wood','driftwood','green wood','cherry wood'],\\\n",
    "'Earth':['peat','moss','musty','leather','compost','wet earth','forest floor','decaying wood'],\\\n",
    "'Mineral':['salt', 'metalllic', 'wet rocks'],\\\n",
    "'Marine':['seawood','ocean air'],\\\n",
    "'Berry':['raspberry','strawberry','blackberry', 'black currant'],\\\n",
    "'Citrus':['lemon','orange','grapefruit','citrus zest'],\\\n",
    "'Tree Fruit':['peach','pear','apricot','apple','cooked fruit','dried fruit'],\\\n",
    "'Tropical':['mango','melon','lychee', 'banana','pineapple'],\n",
    "'Malolactic':['butter']}\n",
    "\n",
    "wheel = {'Earthy':['Wood','Earth','Mineral','Marine'],'Vegetal':['Grass','Vegetables','Herbs'],\\\n",
    "         'Fruity':['Berry','Citrus','Tree Fruit','Tropical']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:15.372393Z",
     "start_time": "2018-06-01T21:45:15.240865Z"
    }
   },
   "outputs": [],
   "source": [
    "#reading a pickle file reading to pick up where i left off in case something fails or i start over\n",
    "with open(\"tea_data.pkl\", 'rb') as picklefile: \n",
    "    teareview_dict = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:16.539627Z",
     "start_time": "2018-06-01T21:45:15.874351Z"
    }
   },
   "outputs": [],
   "source": [
    "#reading in the list of tea dictionaries, each being by itself\n",
    "with open('items_data.pkl', 'rb') as picklefile:\n",
    "    tea_list = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:16.760797Z",
     "start_time": "2018-06-01T21:45:16.542206Z"
    }
   },
   "outputs": [],
   "source": [
    "#reading in the dict of users, user name as key, and 3 lists inside\n",
    "with open('user_data.pkl', 'rb') as picklefile:\n",
    "\n",
    "    user_list = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:21.858361Z",
     "start_time": "2018-06-01T21:45:17.820034Z"
    }
   },
   "outputs": [],
   "source": [
    "#filtering out duplicates\n",
    "new_list=[]\n",
    "for i in tea_list:\n",
    "    if i not in new_list:\n",
    "        new_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:22.091009Z",
     "start_time": "2018-06-01T21:45:21.860577Z"
    }
   },
   "outputs": [],
   "source": [
    "#initializing Mongo Client\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.tea_database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-30T04:16:14.019Z"
    }
   },
   "outputs": [],
   "source": [
    "#to large of a document to insert all at once.\n",
    "users = db.users\n",
    "post_id = users.insert_one(user_list).inserted_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T04:15:15.686586Z",
     "start_time": "2018-05-30T04:15:15.684374Z"
    }
   },
   "outputs": [],
   "source": [
    "teas = db.teas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T04:15:16.752607Z",
     "start_time": "2018-05-30T04:15:16.749426Z"
    }
   },
   "outputs": [],
   "source": [
    "db.collection_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T04:15:33.222074Z",
     "start_time": "2018-05-30T04:15:32.607174Z"
    }
   },
   "outputs": [],
   "source": [
    "#inserting all the teas into mongodb\n",
    "tearesults = teas.insert_many(tea_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-27T01:03:51.429278Z",
     "start_time": "2018-05-27T01:03:51.424482Z"
    }
   },
   "outputs": [],
   "source": [
    "#combining all tea reviews for one tea into a single dictionary\n",
    "reviewcount = []\n",
    "count =0\n",
    "for i in teareview_dict:\n",
    "    count=0\n",
    "    for j in teareview_dict[i]: \n",
    "        count+=len(j['Tea Reviews'])\n",
    "    reviewcount.append(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T18:30:13.522901Z",
     "start_time": "2018-05-28T18:30:13.517593Z"
    }
   },
   "outputs": [],
   "source": [
    "teareview_dict['Black Tea'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:49.820760Z",
     "start_time": "2018-06-01T21:45:49.782885Z"
    }
   },
   "outputs": [],
   "source": [
    "#Cleaning tea names to make them easier to call in flask app\n",
    "itemdf = pd.DataFrame(tea_list)\n",
    "newname=[]\n",
    "import re\n",
    "\n",
    "for i in itemdf['Tea Name']:\n",
    "    line = re.sub('[!@#$\\'\\\",]', '', i)\n",
    "    newname.append(line)\n",
    "itemdf['Tea Name'] = newname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:50.246409Z",
     "start_time": "2018-06-01T21:45:50.231429Z"
    }
   },
   "outputs": [],
   "source": [
    "itemdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:50.858004Z",
     "start_time": "2018-06-01T21:45:50.851501Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating user dataframe\n",
    "userdf = pd.DataFrame.from_dict(user_list, orient='index')\n",
    "userdf.columns = ['tea links','Tea Names', 'Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:52.305574Z",
     "start_time": "2018-06-01T21:45:52.289307Z"
    }
   },
   "outputs": [],
   "source": [
    "userdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:55.019650Z",
     "start_time": "2018-06-01T21:45:55.016041Z"
    }
   },
   "outputs": [],
   "source": [
    "#left in case I decided to take a different decomposition approach\n",
    "\"\"\"for user,i in zip(userdf['Tea Names'], userdf.index):\n",
    "    for ind,j in enumerate(user):\n",
    "        teascore= userdf.loc[i,'Score'][ind]\n",
    "        if teascore=='/span':\n",
    "            teascore=0\n",
    "        teascore_list.append(teascore)\n",
    "userdf = userdf.fillna(0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:56.424724Z",
     "start_time": "2018-06-01T21:45:56.408347Z"
    }
   },
   "outputs": [],
   "source": [
    "userdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## More Data Wrangling\n",
    "\n",
    "Now that I have the dataframe imported, I am going to use NLP to work with the different reviews on certain teas to create more insights and set it up for unsupervised learning.\n",
    "\n",
    "### Tasting Considerations\n",
    "* Aroma: The odor of the tea liquor, also called the nose or fragrance. A complex aroma is often described as a bouquet. \n",
    "* Astringency: A lively and mouth-drying effect on the tongue. Not bitter, but a clean and refreshing quality. The sensation of astringency is caused by a reaction between polyphenols (tannins) and the protein in saliva. \n",
    "* Body: The tactile aspect of tea’s weight and substance in the mouth, variously subcategorized as light, medium, or full; also known as fullness. \n",
    "* Bright: A lively, clean style that refreshes the palate. \n",
    "* Character: A tea’s signature attributes depending upon origin, whether of its country, region or type. \n",
    "* Clean: Indicates purity of flavor and an absence of any off-tastes. \n",
    "* Finish: The lasting taste on your tongue after swallowing the tea. \n",
    "* Flowery: A floral nose or flavor associated with high grade teas. \n",
    "* Full: References a positive sensation of body and good heft; indicates a well-made tea, possessing color, strength, substance and roundness. \n",
    "* Malty: A sweet malt flavor that is characteristic of Assam black teas. \n",
    "* Muscatel: A flavor reminiscent of grapes, most often used to describe an exceptional characteristic found in the liquors of the finest Darjeelings. \n",
    "* Smooth: Round-bodied, fine-drinking teas. \n",
    "* Soft: Smooth, lush, and subsequently often (but not necessarily) timid in flavor; not a negative term. \n",
    "* Thick: Describes liquor having substance, but not necessarily strength. \n",
    "* Vegetal: A characteristic of green teas that might include grassy, herby or marine flavors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T15:39:33.505931Z",
     "start_time": "2018-05-31T15:39:33.502905Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T23:36:05.885000Z",
     "start_time": "2018-05-23T23:36:05.881607Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "teareview_dict['Green Tea'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Polarity Score\n",
    "Using TextBlob, I will be creating a polarity score for each review.  This is to help weight the reviews if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T23:36:16.221575Z",
     "start_time": "2018-05-23T23:36:06.264478Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "polarityscore = []\n",
    "for i in teareview_dict:\n",
    "    for j in teareview_dict[i]: \n",
    "        for review in j['Tea Reviews']:\n",
    "            q = TextBlob(review)\n",
    "            polarityscore.append(q.sentiment.polarity)\n",
    "        j['Polarity']=polarityscore\n",
    "        polarityscore=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T23:36:16.227240Z",
     "start_time": "2018-05-23T23:36:16.223230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "teareview_dict['Black Tea'][0]['Polarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Proportion Flavor Wheel and Mouthfeel\n",
    "\n",
    "Using the flavor wheel found online, I will create a flavor profile for each tea. I will need to use 1 and 2 n-grams and the tastingflavors dictionary.\n",
    "\n",
    "I also want to get any 'mouthfeel' data to see what added bonus it could give to the tea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T14:02:14.988972Z",
     "start_time": "2018-05-30T14:02:14.953218Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#creating flavor profile based on the tastingflavors dict, stored as proportions\n",
    "def getProp(text1):\n",
    "    text1=TextBlob(text1)\n",
    "    count=0\n",
    "    tot_count=0\n",
    "    proportion_dict = {}\n",
    "    for i in tastingflavors:\n",
    "        count=0\n",
    "        adjlist=[]\n",
    "        for j in text1.tags:\n",
    "            if j[1]=='JJ' or j[1]=='JJR'or j[1]=='JJS' or j[1]=='NN'or j[1]=='NNP'or j[1]=='NNS':\n",
    "                abb = re.sub(\"y\",\"\", i[0])\n",
    "                if(i[0] !=abb):\n",
    "                    adjlist.append(abb.lower())\n",
    "                    adjlist.append(j[0].lower())\n",
    "                else:\n",
    "                    adjlist.append(j[0].lower())\n",
    "        for k in adjlist:\n",
    "            if k in tastingflavors[i]:\n",
    "                count+=1\n",
    "        for k in text1.ngrams(n=2):\n",
    "            if ' '.join(k.lower()) in tastingflavors[i]:\n",
    "                count+=1\n",
    "        tot_count+=count\n",
    "        proportion_dict[i]=count\n",
    "    if tot_count!=0:\n",
    "        for i in proportion_dict:\n",
    "            proportion_dict[i] = proportion_dict[i]/tot_count\n",
    "        \n",
    "    return proportion_dict, adjlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T14:02:16.238761Z",
     "start_time": "2018-05-30T14:02:16.210134Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#function pulling out mouthfeel data and filtering out unnecessary data, input is the revlist\n",
    "def getReviews(revlist):\n",
    "    supertext=\"\"\n",
    "    mouthfeel = ''\n",
    "    for i in revlist:\n",
    "        supertext += (' '+ i)\n",
    "        if re.findall(r\"([^[.!]]*?mouthfeel[^.]*\\.)\",i):\n",
    "            mouthfeel=' '.join((re.findall(r\"([^.!,]*?mouthfeel[^.!,]*\\.)\",i)))\n",
    "\n",
    "    supertext = re.sub(\"[’,;:–…]\",\"\", supertext).replace(\"(\", '').replace(\".\", ' ').replace(\"!\", ' ').replace(\")\", '')\n",
    "    supertext= re.sub(\"(-)\",\" \", supertext)\n",
    "    supertext= re.sub(\"(chocolate)\",\"cocoa\", supertext)\n",
    "    word_tokens = word_tokenize(supertext)\n",
    "    sentence = ''\n",
    "    mouthblob = TextBlob(mouthfeel)\n",
    "    mouthadj = []\n",
    "    for i in mouthblob.tags:\n",
    "        if i[1]=='JJ' or i[1]=='JJR'or i[1]=='JJS':\n",
    "            mouthadj.append(i[0])\n",
    "    \n",
    "    \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    for i in filtered_sentence:\n",
    "        sentence += (' '+i)\n",
    "    return supertext, mouthadj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T23:44:25.884226Z",
     "start_time": "2018-05-23T23:36:36.640451Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#creating a flavor profile from both reviews and flavors filled in by customers, also makign a mouthfeel profile if found\n",
    "newdictlist = []\n",
    "for i in teareview_dict:\n",
    "    newdictlist = []\n",
    "    for j in range(len(teareview_dict[i])):\n",
    "        flavtext = ''\n",
    "        reviewtext, mouthfeel= getReviews(teareview_dict[i][j]['Tea Reviews'])\n",
    "        proportions = getProp(reviewtext)\n",
    "        if teareview_dict[i][j]['Tea Flavors']:\n",
    "            flavtext = teareview_dict[i][j]['Tea Flavors']\n",
    "        custproportions= getProp(flavtext)\n",
    "        dict2 = teareview_dict[i][j].copy()\n",
    "        dict2['Mouthfeel']=mouthfeel\n",
    "        dict2['Flavor Profile Cust']=custproportions\n",
    "        dict2['Flavor Profile Reviews']=proportions\n",
    "        dict2['Reviews Supertext']=reviewtext\n",
    "        newdictlist.append(dict2)\n",
    "    teareview_dict[i] = newdictlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T23:44:25.928856Z",
     "start_time": "2018-05-23T23:44:25.885990Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"with open('totstea_data.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(teareview_dict, picklefile)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T23:44:36.440997Z",
     "start_time": "2018-05-23T23:44:25.930787Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "for i in teareview_dict['Green Tea']:\n",
    "    pprint(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans\n",
    "\n",
    "Using Kmeans to cluster my data to create recommendations based on an input vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:37.851517Z",
     "start_time": "2018-06-01T21:45:37.839407Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importing important tools for clustering with scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "vect = CountVectorizer(max_df=.95, min_df=2)\n",
    "tsvd = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:47:16.417546Z",
     "start_time": "2018-06-01T21:47:16.403263Z"
    }
   },
   "outputs": [],
   "source": [
    "#reading a pickle file reading to pick up where i left off in case something fails or i start over\n",
    "with open(\"/Users/deven/Documents/pickleddata/projectfletcher/totstea_data.pkl\", 'rb') as picklefile: \n",
    "    teareview_dict = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:47:22.927128Z",
     "start_time": "2018-06-01T21:47:22.912832Z"
    }
   },
   "outputs": [],
   "source": [
    "#stacking dictionaries into a dataframe\n",
    "teadf = pd.DataFrame()\n",
    "for i in teareview_dict:\n",
    "        newdf = pd.DataFrame.from_dict(teareview_dict[i])\n",
    "        teadf=pd.concat([teadf,newdf],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:47:23.834444Z",
     "start_time": "2018-06-01T21:47:23.758651Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating falvor profile df\n",
    "teaflavdf = pd.DataFrame(list(teadf['Flavor Profile Cust']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:10.025414Z",
     "start_time": "2018-06-01T21:45:10.001925Z"
    }
   },
   "outputs": [],
   "source": [
    "#combining dataframes\n",
    "teadf.reset_index(drop=True,inplace=True)\n",
    "teadf = pd.concat([teadf,teaflavdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:45:10.249441Z",
     "start_time": "2018-06-01T21:45:10.207196Z"
    }
   },
   "outputs": [],
   "source": [
    "teadf.drop('Flavor Profile Reviews', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T14:53:15.980896Z",
     "start_time": "2018-05-25T14:53:15.977872Z"
    }
   },
   "outputs": [],
   "source": [
    "#copying df to experiment with\n",
    "playset = teaflavdf.copy()\n",
    "#teaflavdf=pd.concat([teaflavdf,teaflavdf2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T14:53:22.551012Z",
     "start_time": "2018-05-25T14:53:22.435720Z"
    }
   },
   "outputs": [],
   "source": [
    "#initializing KMeans\n",
    "km = KMeans(n_clusters = 14)\n",
    "km.fit(playset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T14:53:22.947822Z",
     "start_time": "2018-05-25T14:53:22.945392Z"
    }
   },
   "outputs": [],
   "source": [
    "#initializing important variables\n",
    "mu_digits = km.cluster_centers_\n",
    "kmlabels = km.labels_\n",
    "custpref = [ 0,  1.17647059e-02,  0, 0,  0,  0, -4.33680869e-19,  6.93889390e-18,  1.35525272e-20,\\\n",
    "         4.33680869e-19,  5.98930481e-02,  3.46944695e-18, 7.76470588e-02,  6.93889390e-18,  0, 8.50695187e-01,  8.67361738e-19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T14:53:24.019803Z",
     "start_time": "2018-05-25T14:53:24.009766Z"
    }
   },
   "outputs": [],
   "source": [
    "#defining a function to find the closest teas to a specific flavor profile based on euclidean distance, returns (index, dist) pair\n",
    "def Rec(labels, clstr,cust):\n",
    "    clustlist = []\n",
    "    tearecs=[]\n",
    "    teaind=[]\n",
    "    for ind, i in enumerate(labels):\n",
    "        if i ==clstr:\n",
    "            clustlist.append(ind)\n",
    "    newdf= playset.iloc[clustlist,:]\n",
    "    for i in range(len(newdf)):\n",
    "        tearecs.append((newdf.index[i],sum(euclidean_distances([newdf.iloc[i,:]], [cust]))/len(euclidean_distances([newdf.iloc[i,:]], [cust]))))\n",
    "    mindist = sorted(tearecs)\n",
    "    return tearecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T14:53:24.617886Z",
     "start_time": "2018-05-25T14:53:24.605062Z"
    }
   },
   "outputs": [],
   "source": [
    "tearecs = Rec(kmlabels,km.predict([custpref])[0],custpref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T14:53:25.172520Z",
     "start_time": "2018-05-25T14:53:25.167363Z"
    }
   },
   "outputs": [],
   "source": [
    "#Defining a function that takes tea rec (index,dist), then pulls the tea names based on smallest dist values\n",
    "def getTeaNames(tearec):\n",
    "    teanames = []\n",
    "    mindist = sorted(tearec, key=lambda x:x[1])\n",
    "    teanames = [w[0] for w in mindist[:3]]\n",
    "    teanames = teadf.iloc[teanames,:]['Tea Name']\n",
    "    return teanames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T14:53:25.748587Z",
     "start_time": "2018-05-25T14:53:25.742829Z"
    }
   },
   "outputs": [],
   "source": [
    "teanames = getTeaNames(tearecs)\n",
    "teanames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining amount of Clusters\n",
    "\n",
    "Using the silhoutte score to find the optimal cluster amount.  Also, testing out which clustering method is the best for my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T02:27:15.653272Z",
     "start_time": "2018-05-25T02:27:15.650642Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing functions\n",
    "from sklearn.cluster import SpectralClustering, AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T02:27:16.228277Z",
     "start_time": "2018-05-25T02:27:16.225334Z"
    }
   },
   "outputs": [],
   "source": [
    "#initializing functions\n",
    "sc = SpectralClustering()\n",
    "ac = AgglomerativeClustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T02:32:49.521749Z",
     "start_time": "2018-05-25T02:32:49.517925Z"
    }
   },
   "outputs": [],
   "source": [
    "db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T21:44:56.368116Z",
     "start_time": "2018-06-01T21:44:55.473357Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#using Spectral clustering, find the best silhouette score based on increasing k values\n",
    "Sil_coefs = []\n",
    "for k in range(2,20):\n",
    "    sc = SpectralClustering(n_clusters = k)\n",
    "    sc.fit(teaflavdf)\n",
    "    labels = sc.labels_\n",
    "    Sil_coefs.append(metrics.silhouette_score(teaflavdf, labels, metric='euclidean'))\n",
    "fig, ax1 = plt.subplots(1,1, figsize=(15,5), sharex=True)\n",
    "k_clusters = range(2,20)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.plot(k_clusters, sc.inertia_)\n",
    "ax1.set_title('Spectral Cluster')\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_ylabel('silhouette coefficient')\n",
    "plt.xticks(np.arange(2, 20, step=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T02:41:40.969162Z",
     "start_time": "2018-05-25T02:41:39.600182Z"
    }
   },
   "outputs": [],
   "source": [
    "#using agglomerative clustering, find the best silhouette score based on increasing k values\n",
    "Sil_coefs = []\n",
    "for k in range(2,20):\n",
    "    ac = AgglomerativeClustering(n_clusters = k)\n",
    "    ac.fit(teaflavdf)\n",
    "    labels = ac.labels_\n",
    "    Sil_coefs.append(metrics.silhouette_score(teaflavdf, labels, metric='euclidean'))\n",
    "fig, ax1 = plt.subplots(1,1, figsize=(15,5), sharex=True)\n",
    "k_clusters = range(2,20)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_ylabel('silhouette coefficient')\n",
    "ax1.set_title('Agg Cluster')\n",
    "plt.xticks(np.arange(2, 20, step=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T02:41:00.714186Z",
     "start_time": "2018-05-25T02:40:58.524662Z"
    }
   },
   "outputs": [],
   "source": [
    "#using KMeans clustering, find the best silhouette score based on increasing k values\n",
    "Sil_coefs = []\n",
    "for k in range(2,20):\n",
    "    km = KMeans(n_clusters=k, random_state=1)\n",
    "    km.fit(teaflavdf)\n",
    "    labels = km.labels_\n",
    "    Sil_coefs.append(metrics.silhouette_score(teaflavdf, labels, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T02:42:18.725289Z",
     "start_time": "2018-05-25T02:42:18.557226Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,1, figsize=(15,5), sharex=True)\n",
    "k_clusters = range(2,20)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_title('KMeans Cluster')\n",
    "ax1.set_ylabel('silhouette coefficient')\n",
    "plt.xticks(np.arange(2, 20, step=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flavor Profile PCA\n",
    "\n",
    "Looking at the distribution of flavor profile data if fitted to 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teadf = teadf.set_index('Tea Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewvect = vect.fit_transform(teadf[['Reviews Supertext','Tea Flavors']])\n",
    "#flavvect = vect.fit_transform(teadf['Tea Flavors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(reviewvect.toarray(), index=example, columns=vectorizer.get_feature_names()).head(10)\n",
    "dtm = dtm.asfptype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T15:04:34.765923Z",
     "start_time": "2018-05-25T15:04:34.763022Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T15:04:35.202543Z",
     "start_time": "2018-05-25T15:04:35.181823Z"
    }
   },
   "outputs": [],
   "source": [
    "principalComponents = pca.fit_transform(teaflavdf)\n",
    "X = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T15:04:36.410908Z",
     "start_time": "2018-05-25T15:04:35.699589Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X['principal component 1'], X['principal component 2'], c=kmlabels, s=50, cmap='viridis')\n",
    "\n",
    "centers = km.cluster_centers_\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-25T15:04:36.425212Z",
     "start_time": "2018-05-25T15:04:36.414265Z"
    }
   },
   "outputs": [],
   "source": [
    "principalDf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD with Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T22:54:07.570651Z",
     "start_time": "2018-05-31T22:54:07.558377Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from surprise import NormalPredictor\n",
    "from surprise import SVDpp,SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T22:54:08.129164Z",
     "start_time": "2018-05-31T22:54:08.087393Z"
    }
   },
   "outputs": [],
   "source": [
    "userdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T22:54:09.891857Z",
     "start_time": "2018-05-31T22:54:09.369121Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating a df for surprise analysis from userdf \n",
    "teascore_list=[]\n",
    "teauser_list=[]\n",
    "teaname_list=[]\n",
    "        \n",
    "for user,i in zip(userdf['Tea Names'], userdf.index):\n",
    "    for ind,j in enumerate(user):\n",
    "        teascore= userdf.loc[i,'Score'][ind]\n",
    "        if teascore=='/span':\n",
    "            teascore=0\n",
    "        teascore_list.append(teascore)\n",
    "        teauser_list.append(i)\n",
    "        teaname_list.append(re.sub('[!@#$\\'\\\",]', '', j))\n",
    "newdf=pd.DataFrame({'Tea Name': teaname_list,\n",
    "     'Score': teascore_list,\n",
    "     'User Name': teauser_list\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T14:42:44.217417Z",
     "start_time": "2018-05-31T14:42:44.189664Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"with open('surprise_data.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(newdf, picklefile)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:13:49.282048Z",
     "start_time": "2018-05-31T23:13:49.274738Z"
    }
   },
   "outputs": [],
   "source": [
    "#adding names and classes from survey\n",
    "names = ['maya','THE Jonathan', 'Kelly', 'Amy', 'Sakura', 'Dan','Anonymous','Travis', 'Chad', 'the_og_jonathan','Vicky', 'Cyrus', 'Deven']\n",
    "teas = ['Irish Breakfast','Earl Grey', 'Pre Rain Organic Dragon Well Supreme (Long Jing)', 'supreme pu-erh', 'Loose leaf white teas', 'Gyokuro', 'Chai',\\\n",
    "        'Peppermint Tea', 'chamomile','rishi tropical hibiscus', 'organic english breakfast','jasmine dragon pearls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:13:49.806558Z",
     "start_time": "2018-05-31T23:13:49.800704Z"
    }
   },
   "outputs": [],
   "source": [
    "teas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:13:50.642087Z",
     "start_time": "2018-05-31T23:13:50.631279Z"
    }
   },
   "outputs": [],
   "source": [
    "#adding classmate scores, all of this needed to be hard coded\n",
    "classrate=[]\n",
    "classrate=[[55,95,25,45,0,25,85,90,0,0,0,0],[5,75,95,20,80,25,85,25,25,0,80,0], [75,95,85,85,55,85,65,0,95,0,0,0], \\\n",
    "[95,35,65,0,0,35,5,0,0,85,0,0],[95,75,65,55,45,55,15,0,0,0,0,0],[45,55,55,15,15,55,65,75,0,0,0,0],\\\n",
    "[95,95,0,15,0,0,95,0,0,0,0,0], [95,95,25,35,0,25,75,0,0,0,95,0], [55,65,85,0,95,75,45,0,0,0,0,0],\\\n",
    "[55,55,75,45,75,75,95,95,0,0,0,0],[35,35,95,95,45,95,95,0,0,0,0,90],[65,65,55,0,15,85,95,0,0,0,0,0],\\\n",
    "[35,75,86,55,70,85,75,85,85,65,40,90]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:13:54.507025Z",
     "start_time": "2018-05-31T23:13:53.684098Z"
    }
   },
   "outputs": [],
   "source": [
    "for index,i in enumerate(names):\n",
    "    for ind, k in enumerate(classrate[index]):\n",
    "        newdf = pd.concat([newdf,pd.DataFrame([[k,teas[ind], i]], columns = ['Score', 'Tea Name', 'User Name'])], ignore_index=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:13:56.562668Z",
     "start_time": "2018-05-31T23:13:55.547617Z"
    }
   },
   "outputs": [],
   "source": [
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(0, 100))\n",
    "algo=SVD()\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(newdf[['User Name', 'Tea Name', 'Score']], reader)\n",
    "\n",
    "# We can now use this dataset as we please, e.g. calling cross_validate\n",
    "cross_validate(NormalPredictor(), data, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:14:07.172813Z",
     "start_time": "2018-05-31T23:13:56.565508Z"
    }
   },
   "outputs": [],
   "source": [
    "#SVD is a better predictor, albeit still a bit off\n",
    "cross_validate(algo, data, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:14:07.189134Z",
     "start_time": "2018-05-31T23:14:07.176772Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_top_n(predictions, n=3):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T00:09:30.671885Z",
     "start_time": "2018-06-01T00:09:27.271906Z"
    }
   },
   "outputs": [],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T00:16:38.224735Z",
     "start_time": "2018-06-01T00:09:30.673643Z"
    }
   },
   "outputs": [],
   "source": [
    "#generating predictions for unrated teas based on what users have rated\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T00:16:49.487515Z",
     "start_time": "2018-06-01T00:16:38.240715Z"
    }
   },
   "outputs": [],
   "source": [
    "want= []\n",
    "for i in predictions:\n",
    "    if i[0] in names:\n",
    "        want.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T00:16:49.704642Z",
     "start_time": "2018-06-01T00:16:49.493991Z"
    }
   },
   "outputs": [],
   "source": [
    "top_n = get_top_n(want, n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:26:37.226655Z",
     "start_time": "2018-05-31T23:26:37.176186Z"
    }
   },
   "outputs": [],
   "source": [
    "recsdf = pd.DataFrame(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:26:41.851715Z",
     "start_time": "2018-05-31T23:26:41.788995Z"
    }
   },
   "outputs": [],
   "source": [
    "recsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T18:37:32.895984Z",
     "start_time": "2018-05-28T18:37:32.867093Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words = stop_words + ['the','i','I','a','of',')','\\'', 'to', 'it','and','is','this','for', 'but', 'that', 'in', 'my', 'not','husband',\\\n",
    "            'be', 'we', 'are', 'm', 'as', 'just', 'there', 'you','all','with','me', 'few', 'will', 'on','has', 'was','many','last'\\\n",
    "              '''()''', \"'\",'!','.','It',',', '-',':','Thanksgiving','tea','Im','youll','Ive','Its','Also','A','As','This','cant','anybody',\\\n",
    "               'go','one','everybody','dont', 'We', 'us', 'got', 'And']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T19:19:40.077066Z",
     "start_time": "2018-05-28T18:37:33.883303Z"
    }
   },
   "outputs": [],
   "source": [
    "#adding flavor profiles to allow for a hybrid approach\n",
    "newdictlist = []\n",
    "dict2={}\n",
    "totsteareviews = []\n",
    "for j in tea_list:\n",
    "    flavtext = ''\n",
    "    reviewtext=''\n",
    "    dict2={}\n",
    "    adjlist=[]\n",
    "    flavs = []\n",
    "    reviewtext, mouthfeel= getReviews(j['Tea Reviews'])\n",
    "    proportions, adjlist = getProp(reviewtext)\n",
    "    if j['Tea Flavors']!='<dd class=\"empty\">Not available':\n",
    "        flavtext = j['Tea Flavors']\n",
    "        custproportions, flavs= getProp(flavtext)\n",
    "        dict2['Flavor Profile Cust']=custproportions\n",
    "    else: \n",
    "        dict2['Flavor Profile Cust']=0\n",
    "    dict2['Review Adj'] = adjlist+flavs\n",
    "    dict2['Tea Name'] = j['Tea Name']\n",
    "    dict2['Mouthfeel']=mouthfeel\n",
    "    dict2['Flavor Profile Reviews']=proportions\n",
    "    dict2['Reviews Supertext']=reviewtext\n",
    "    totsteareviews.append(reviewtext)\n",
    "    newdictlist.append(dict2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-28T19:27:47.091723Z",
     "start_time": "2018-05-28T19:27:47.080869Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"#saving list as it takes forever for it to run\n",
    "with open(\"newdatalist.pkl\", 'wb') as picklefile: \n",
    "    pickle.dump(newdictlist,picklefile)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T15:06:28.048110Z",
     "start_time": "2018-05-31T15:06:27.408420Z"
    }
   },
   "outputs": [],
   "source": [
    "#reading in the list of users\n",
    "with open('/Users/deven/Documents/pickleddata/projectfletcher/newdatalist.pkl', 'rb') as picklefile:\n",
    "    newdictlist = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T15:06:30.859784Z",
     "start_time": "2018-05-31T15:06:30.837081Z"
    }
   },
   "outputs": [],
   "source": [
    "newteaprofiledf = pd.DataFrame(newdictlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:30:32.907784Z",
     "start_time": "2018-05-31T23:30:32.810929Z"
    }
   },
   "outputs": [],
   "source": [
    "#flavor profile Cust is the most accurate\n",
    "newteaprofiledf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hybrid Model\n",
    "\n",
    "Creating a linear regresssion model to predict the 'actual' predicted rating of teas to counter the 'cold start up' problem in collaborative recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#initializing the get functions to find nearest points\n",
    "def Rec(labels, clstr,cust):\n",
    "    clustlist = []\n",
    "    tearecs=[]\n",
    "    teaind=[]\n",
    "    for ind, i in enumerate(labels):\n",
    "        if i ==clstr:\n",
    "            clustlist.append(ind)\n",
    "    newdf= playset.iloc[clustlist,:]\n",
    "    for i in range(len(newdf)):\n",
    "        tearecs.append((newdf.index[i],sum(euclidean_distances([newdf.iloc[i,:]], [cust]))/len(euclidean_distances([newdf.iloc[i,:]], [cust]))))\n",
    "    mindist = sorted(tearecs)\n",
    "    return tearecs\n",
    "def getTeaNames(tearec):\n",
    "    teanames = []\n",
    "    mindist = sorted(tearec, key=lambda x:x[1])\n",
    "    teanames = [w[0] for w in mindist[:3]]\n",
    "    teanames = teadf.iloc[teanames,:]['Tea Name']\n",
    "    return teanames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_n[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#trying to find which of the top 10 are closest to the other teas the user has tried, based on average, may need to rethink this \n",
    "avetearate = []\n",
    "tearate = 0\n",
    "count=0\n",
    "flag=0\n",
    "for i in top_n:\n",
    "    for k in top_n[i]:\n",
    "        userrecs = newdf[newdf['User Name']==i]['Tea Name']\n",
    "        avetearate=[]\n",
    "        if len(userrecs) <5:\n",
    "            if flag==1:\n",
    "                break\n",
    "            count=0\n",
    "            for i in userrecs['Tea Name']:\n",
    "                eudis=(euclidean_distances(newteaprofiledf[newteaprofiledf['Tea Name']==i]['Flavor Profile Reviews'], newteaprofiledf[newteaprofiledf['Tea Name']==k[0]]['Flavor Profile Reviews']))\n",
    "                tearate +=eudis\n",
    "                count+=1\n",
    "            avetearate.append((tearate/count))\n",
    "            tearate=0\n",
    "        flag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T14:07:35.505331Z",
     "start_time": "2018-05-30T14:07:35.500945Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = newteaprofiledf[['Tea Name', 'Flavor Profile Cust']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T14:11:35.441936Z",
     "start_time": "2018-05-30T14:11:35.405190Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hybrid1 = pd.merge(newdf,df1,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T14:15:27.807073Z",
     "start_time": "2018-05-30T14:15:27.777522Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "newcols=[]\n",
    "for i in hybrid1['Flavor Profile Cust']:\n",
    "    newcols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-30T14:21:43.641Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inter = pd.DataFrame(newcols)\n",
    "print(len(inter))\n",
    "print(len(hybrid1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-30T14:21:59.489Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hybrid1 = pd.concat([hybrid1, inter], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hybrid1.drop('Flavor Profile Cust', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hybrid1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "algopredicts = []\n",
    "for i,k in zip(hybrid1['Tea Name'],hybrid1['User Name']):\n",
    "    algopredicts.append(round(algo.predict(k, i).est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hybrid1['Algo']=algopredicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hybrid1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hybrid1['Algo'] = preprocessing.scale(hybrid1['Algo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hybrid1['Score'] = preprocessing.scale(hybrid1['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = hybrid1['Score']\n",
    "X = hybrid1.drop(['Tea Name','User Name','Score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#hybriddf = pd.DataFeame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X,y, test_size=.3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#lg.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "est =  ElasticNetCV(l1_ratio = .15, cv=20, n_alphas= 200)\n",
    "est.fit(xtrain,ytrain)\n",
    "est.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Getting multiplicative error to see my models absolute fit\n",
    "rms = math.sqrt(mean_squared_error(ytest, est.predict(xtest)))\n",
    "math.exp(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def diagnostic_plot(x, y):\n",
    "    plt.figure(figsize=(20,5))\n",
    "        \n",
    "    pred = lr.predict(x)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    res = y - pred\n",
    "    plt.scatter(pred, res)\n",
    "    plt.title(\"Residual plot\")\n",
    "    plt.xlabel(\"prediction\")\n",
    "    plt.ylabel(\"residuals\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    #Generates a probability plot of sample data against the quantiles of a \n",
    "    # specified theoretical distribution \n",
    "    stats.probplot(res, dist=\"norm\", plot=plt)\n",
    "    plt.title(\"Normal Q-Q plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Checking residuals and quantile plots\n",
    "#diagnostic_plot(xtest, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Doc2Vec\n",
    "\n",
    "Experimenting with Doc2vec to see if there is any relation between tea reviews based on tea type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T15:39:20.787996Z",
     "start_time": "2018-05-31T15:39:20.111641Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "itemdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train=[]\n",
    "test=[]\n",
    "words=''\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    for i in fname:\n",
    "        for k,line in enumerate(i):\n",
    "            if tokens_only:\n",
    "                yield gensim.utils.simple_preprocess(line)\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                if len(gensim.utils.simple_preprocess(line))<50:\n",
    "                    yield gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(gensim.utils.simple_preprocess(itemdf['Tea Reviews'][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train = itemdf['Tea Reviews'][:round(len(itemdf)*.8)]\n",
    "test = itemdf['Tea Reviews'][-round((len(itemdf)*.2)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(train))\n",
    "test_corpus = list(read_corpus(test, tokens_only=True))\n",
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#model.save('teadocmodel.bin')\n",
    "model = gensim.models.doc2vec.Doc2Vec.load('teadocmodel.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec with Books\n",
    "\n",
    "Using doc to vec to see if I can recommend books based on tea flavor profiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:27:41.416984Z",
     "start_time": "2018-05-31T23:27:41.408016Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books = nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:27:41.875831Z",
     "start_time": "2018-05-31T23:27:41.869084Z"
    }
   },
   "outputs": [],
   "source": [
    "bookt = ['Emma by Jane Austen', 'Persuassion by Jane Austen', 'Sense and Sensibility by Jane Austen',\\\n",
    "        'Poems by William Blake', 'The Little People of the Snow by William Bryant', 'The Adventures of Buster Bear by Thornton Burgress'\\\n",
    "        'Alice in Wonderland by Lewis Carroll','The Ball and the Cross by G.K. Chesterton','The Wisdom of Father Brown by G.K. Chesterton'\\\n",
    "        'The Ball and the Cross by G.K. Chesterton', 'The Parents Assistant by Maria Edgeworth','Moby Dick by Herman Melville',\\\n",
    "        'Paradise Lost by John Milton', 'Shakespeares Works','Shakespeares Works','Shakespeares Works', 'Leaves of Grass by Walt Whitman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:27:42.494146Z",
     "start_time": "2018-05-31T23:27:42.489611Z"
    }
   },
   "outputs": [],
   "source": [
    "beat = {}\n",
    "for i,k in zip(books, bookt):\n",
    "    beat[i]=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:27:43.099223Z",
     "start_time": "2018-05-31T23:27:43.073345Z"
    }
   },
   "outputs": [],
   "source": [
    "doclen = []\n",
    "train = []\n",
    "def read_corpus1(fname, tokens_only=False):\n",
    "    for i in fname:\n",
    "        for k,line in enumerate(i):\n",
    "            if tokens_only:\n",
    "                train.append(gensim.utils.simple_preprocess(line))\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                if len(gensim.utils.simple_preprocess(line))<50:\n",
    "                    train.append(gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(line), [k]))\n",
    "        doclen.append(k)\n",
    "    return train, doclen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:27:45.624826Z",
     "start_time": "2018-05-31T23:27:45.607928Z"
    }
   },
   "outputs": [],
   "source": [
    "bookrec = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:27:47.923180Z",
     "start_time": "2018-05-31T23:27:46.076423Z"
    }
   },
   "outputs": [],
   "source": [
    "bookwords=[]\n",
    "for i in books:\n",
    "    book = ' '.join(nltk.corpus.gutenberg.words(i))\n",
    "    bookwords.append(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:31:03.748937Z",
     "start_time": "2018-05-31T23:30:58.727760Z"
    }
   },
   "outputs": [],
   "source": [
    "btrain,doclen = list(read_corpus1(bookwords))\n",
    "test_corpus = newteaprofiledf['Review Adj'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:55:49.443479Z",
     "start_time": "2018-06-01T01:55:49.420769Z"
    }
   },
   "outputs": [],
   "source": [
    "'''with open(\"doclen.pkl\", 'wb') as picklefile: \n",
    "    pickle.dump(doclen,picklefile)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:33:51.900063Z",
     "start_time": "2018-05-31T23:31:31.877052Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/Users/deven/Documents/pickleddata/projectfletcher/btrain.pkl', 'rb') as picklefile:\n",
    "    btrain = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrec.build_vocab(btrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:35:56.596322Z",
     "start_time": "2018-05-31T23:35:55.639878Z"
    }
   },
   "outputs": [],
   "source": [
    "bookrec = gensim.models.doc2vec.Doc2Vec.load('/Users/deven/Documents/pickleddata/projectfletcher/bookrec.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:18:13.814919Z",
     "start_time": "2018-06-01T01:18:12.186250Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = bookrec.infer_vector(test_corpus[doc_id])\n",
    "sims = bookrec.docvecs.most_similar([inferred_vector])\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % bookrec)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2)]:\n",
    "    print(u'%s %s: \\n' % (label, sims[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot=0\n",
    "for ind, i in enumerate(doclen):\n",
    "    tot+=i\n",
    "    if sims[0][0]==btrain[ind][1]:\n",
    "        rec = nltk.corpus.gutenberg.fileids()[ind-1]\n",
    "        break\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:44:23.447008Z",
     "start_time": "2018-05-31T23:44:23.436859Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBookrec(iid):\n",
    "    test_corpus = newteaprofiledf[newteaprofiledf['Tea Name']==iid]['Review Adj'].values[0]\n",
    "    inferred_vector = bookrec.infer_vector(test_corpus)\n",
    "    sims = bookrec.docvecs.most_similar([inferred_vector])\n",
    "    rec=''\n",
    "    tot=0\n",
    "    for ind, i in enumerate(doclen):\n",
    "        tot+=i\n",
    "        if sims[0][0]<tot:\n",
    "            rec = bookt[ind-1]\n",
    "            break\n",
    "    return rec,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:44:27.191161Z",
     "start_time": "2018-05-31T23:44:23.824360Z"
    }
   },
   "outputs": [],
   "source": [
    "bookreclist = []\n",
    "for i in names:\n",
    "    teaid= top_n[i][0][0]\n",
    "    bookreclist.append(getBookrec(teaid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T23:44:57.706830Z",
     "start_time": "2018-05-31T23:44:57.703130Z"
    }
   },
   "outputs": [],
   "source": [
    "print(bookreclist)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:30:40.434160Z",
     "start_time": "2018-06-01T01:30:40.420944Z"
    }
   },
   "outputs": [],
   "source": [
    "frec=[]\n",
    "srec=[]\n",
    "trec=[]\n",
    "for i in top_n:\n",
    "    frec.append(top_n[i][0][0])\n",
    "    srec.append(top_n[i][1][0])\n",
    "    trec.append(top_n[i][2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:18:17.773488Z",
     "start_time": "2018-06-01T01:18:17.759139Z"
    }
   },
   "outputs": [],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bookrec.save('bookrec.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:26:56.551601Z",
     "start_time": "2018-06-01T01:26:56.542401Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='djmorcode', api_key='g4D9PR85TaaUkKlH8CWZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:35:48.604087Z",
     "start_time": "2018-06-01T01:35:46.887368Z"
    }
   },
   "outputs": [],
   "source": [
    "trace = go.Table(\n",
    "    header=dict(values=['Name', 'Tea Rec 1','Tea Rec 2','Tea Rec 3','Book Recommendation'],\n",
    "                line = dict(color='#7D7F80'),\n",
    "                fill = dict(color='#a1c3d1'),\n",
    "                align = ['left'] * 5),\n",
    "    cells=dict(values=[names,frec,srec,trec,bookreclist],\n",
    "               line = dict(color='#7D7F80'),\n",
    "               fill = dict(color='#EDFAFF'),\n",
    "               align = ['left'] * 5))\n",
    "\n",
    "layout = dict(width=1000, height=800)\n",
    "data = [trace]\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'styled_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:44:22.997349Z",
     "start_time": "2018-06-01T01:44:22.938200Z"
    }
   },
   "outputs": [],
   "source": [
    "top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T02:33:00.087696Z",
     "start_time": "2018-06-01T02:32:59.936557Z"
    }
   },
   "outputs": [],
   "source": [
    "print(bookreclist)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LDA Books\n",
    "\n",
    "Trying the recommendation system with LDA for recommending books.  ***Work in progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities, matutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 2),  \n",
    "                                   stop_words=stop_words)\n",
    "cv.fit(bookwords)\n",
    "teawords = cv.transform(newteaprofiledf['Review Adj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating matrix, then transposing it so the terms are the rows\n",
    "counts = cv.transform(bookwords).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Convert sparse matrix of counts to a gensim corpus\n",
    "corpus = matutils.Sparse2Corpus(counts)\n",
    "compareset = matutils.Sparse2Corpus(teawords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#saving mapping for later use\n",
    "id2word = dict((v, k) for k, v in count_vectorizer.vocabulary_.items())\n",
    "id2word = dict((v, k) for k, v in count_vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus=corpus, num_topics=5, minimum_probability=0.03, id2word=id2word, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus=corpus, num_topics=5, minimum_probability=0.03, id2word=id2word, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Transform the docs from the word space to the topic space (like \"transform\" in sklearn)\n",
    "lda_corpus = lda[corpus]\n",
    "lda_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store the documents' topic vectors in a list so we can take a peak\n",
    "lda_docs = [doc for doc in lda_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check out the document vectors in the topic space for the first 5 documents\n",
    "lda_docs[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Word2Vec\n",
    "\n",
    "Tryign my hand at word to vec to see if it will work for a NLP analysis of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "allwords = nltk.corpus.gutenberg.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(allwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(fname):\n",
    "    for i in fname:\n",
    "        for line in i:\n",
    "            if len(gensim.utils.simple_preprocess(line))<50:\n",
    "                 yield [x for x in gensim.utils.simple_preprocess(line) if len(x)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(train))\n",
    "test_corpus = list(read_corpus(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model1 = gensim.models.Word2Vec(train_corpus, size=100, window=5, min_count=1, workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#model1.save('teawordmodel.bin')\n",
    "model1 = gensim.models.word2vec.Word2Vec.load('teawordmodel.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(model.wv.vocab.items())[:7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(model['bright'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Similarity\n",
    "model.most_similar('mouthfeel' ,topn=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.similarity('green','tea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.n_similarity(['bread', 'dog'], ['cat', 'dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.doesnt_match(\"rabbit cow raven turtle\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating wrappers\n",
    "\n",
    "Creating a list of wrappers to copy into a JS file for flask app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Giving wrappers a try\n",
    "def p_decorate(func):\n",
    "   def func_wrapper(name):\n",
    "       return \"{\"+func(name)+\"},\"\n",
    "   return func_wrapper\n",
    "@p_decorate\n",
    "def getval(string):\n",
    "    return 'value: +{0}+,'.format(string)+'\\n'+' text: +{0}+'.format(string)\n",
    "convert_text = p_decorate(getval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loopit(list1):\n",
    "    new_list = []\n",
    "    for i in list1:\n",
    "        new_list.append(getval(i))\n",
    "        \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "uniteas = loopit(itemdf['Tea Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(uniteas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
