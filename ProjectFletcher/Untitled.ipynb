{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:58:04.178772Z",
     "start_time": "2018-06-01T01:56:22.004993Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import flask\n",
    "from flask import Flask\n",
    "import pickle\n",
    "import random\n",
    "from surprise import SVDpp,SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "#pulling in dataset, item list\n",
    "with open('/Users/deven/Documents/pickleddata/projectfletcher/newdatalist.pkl', 'rb') as picklefile:\n",
    "    itemdf = pickle.load(picklefile)\n",
    "with open('/Users/deven/Documents/GitHub/Metis/ProjectFletcher/surprise_data.pkl', 'rb') as picklefile:\n",
    "    newdf = pickle.load(picklefile)\n",
    "with open('/Users/deven/Documents/pickleddata/projectfletcher/btrain.pkl', 'rb') as picklefile:\n",
    "    btrain = pickle.load(picklefile)\n",
    "with open('doclen.pkl', 'rb') as picklefile:\n",
    "    doclen = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T01:58:04.311010Z",
     "start_time": "2018-06-01T01:58:04.185728Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import flask\n",
    "from flask import Flask\n",
    "import pickle\n",
    "import random\n",
    "from surprise import SVDpp,SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "#pulling in dataset, item list\n",
    "with open('/Users/deven/Documents/pickleddata/projectfletcher/newdatalist.pkl', 'rb') as picklefile:\n",
    "    itemdf = pickle.load(picklefile)\n",
    "with open('/Users/deven/Documents/GitHub/Metis/ProjectFletcher/surprise_data.pkl', 'rb') as picklefile:\n",
    "    newdf = pickle.load(picklefile)\n",
    "with open('/Users/deven/Documents/pickleddata/projectfletcher/btrain.pkl', 'rb') as picklefile:\n",
    "    btrain = pickle.load(picklefile)\n",
    "with open('doclen.pkl', 'rb') as picklefile:\n",
    "    doclen = pickle.load(picklefile)\n",
    "#changing some tea names for easier calls\n",
    "itemdf = pd.DataFrame(itemdf)\n",
    "newname=[]\n",
    "import re\n",
    "\n",
    "for i in itemdf['Tea Name']:\n",
    "    line = re.sub('[!@#$\\'\\\",]', '', i)\n",
    "    newname.append(line)\n",
    "itemdf['Tea Name'] = newname\n",
    "\n",
    "#initializing book list\n",
    "bookt = ['Emma by Jane Austen', 'Persuassion by Jane Austen', 'Sense and Sensibility by Jane Austen',\\\n",
    "        'Poems by William Blake', 'The Little People of the Snow by William Bryant', 'The Adventures of Buster Bear by Thornton Burgress'\\\n",
    "        'Alice in Wonderland by Lewis Carroll','The Ball and the Cross by G.K. Chesterton','The Wisdom of Father Brown by G.K. Chesterton'\\\n",
    "        'The Ball and the Cross by G.K. Chesterton', 'The Parents Assistant by Maria Edgeworth','Moby Dick by Herman Melville',\\\n",
    "        'Paradise Lost by John Milton', 'Shakespeares Works','Shakespeares Works','Shakespeares Works', 'Leaves of Grass by Walt Whitman']\n",
    "\n",
    "imagelocs = {'Emma by Jane Austen':'static/emma.jpg','Persuassion by Jane Austen':'static/persuassion.jpg','Sense and Sensibility by Jane Austen':'static/sense.jpg',\\\n",
    "'Poems by William Blake':'static/blake.jpg','The Little People of the Snow by William Bryant':'static/bryant.jpg','The Adventures of Buster Bear by Thornton Burgress':'static/the-adventures-of-buster-bear.jpg',\\\n",
    "'Alice in Wonderland by Lewis Carroll':'static/alice.jpg', 'The Ball and the Cross by G.K. Chesterton':'static/ball.jpg','The Wisdom of Father Brown by G.K. Chesterton':'static/fatherbrown.jpg',\\\n",
    "'The Parents Assistant by Maria Edgeworth':'static/edge.jpg','Moby Dick by Herman Melville':'static/moby.jpg','Paradise Lost by John Milton':'static/paradise.jpg',\\\n",
    "'Shakespeares Works':'static/shake.jpg','Shakespeares Works':'static/shake.jpg','Shakespeares Works':'static/shake.jpg','Leaves of Grass by Walt Whitman':'static/leaves.jpg'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T02:36:09.614576Z",
     "start_time": "2018-06-01T02:36:09.317100Z"
    }
   },
   "outputs": [],
   "source": [
    "#Call function for top ratings\n",
    "from collections import defaultdict\n",
    "def get_top_n(teaid,score,qq, n=3):\n",
    "    # A reader is still needed but only the rating_scale param is requiered.\n",
    "    qq = pd.concat([qq,pd.DataFrame([[score,teaid, 'user1']], columns = ['Score', 'Tea Name', 'User Name'])], ignore_index=True)\n",
    "    reader = Reader(rating_scale=(0, 100))\n",
    "    algo=SVD()\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    data = Dataset.load_from_df(newdf[['User Name', 'Tea Name', 'Score']], reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    testset = trainset.build_anti_testset()\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "    want= []\n",
    "    for i in predictions:\n",
    "        if i[0]== 'user1':\n",
    "            want.append(i)\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in want:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    teadist = []\n",
    "    mindist = []\n",
    "    eudist=0\n",
    "    for i in top_n['user1']:\n",
    "        eudis=(euclidean_distances(teadf.iloc[itemdf[itemdf['Tea Name']==x[0]].index,:], \\\n",
    "            teadf.iloc[itemdf[itemdf['Tea Name']==i[0]].index,:]))\n",
    "        teadist.append((i[0],eudist))\n",
    "    mindist = sorted(teadist, key=lambda x:x[1])\n",
    "\n",
    "    return mindist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T02:36:10.187248Z",
     "start_time": "2018-06-01T02:36:10.164934Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBookrec(iid):\n",
    "    bookrec = gensim.models.doc2vec.Doc2Vec.load('/Users/deven/Documents/pickleddata/projectfletcher/bookrec.bin')\n",
    "    test_corpus = itemdf[itemdf['Tea Name']==iid]['Review Adj'].values[0]\n",
    "    inferred_vector = bookrec.infer_vector(test_corpus)\n",
    "    sims = bookrec.docvecs.most_similar([inferred_vector])\n",
    "    rec=''\n",
    "    tot=0\n",
    "    for ind, i in enumerate(doclen):\n",
    "        tot+=i\n",
    "        if sims[0][0]<tot:\n",
    "            rec = bookt[ind-1]\n",
    "            break\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-01T02:36:10.872024Z",
     "start_time": "2018-06-01T02:36:10.866522Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {'example':['Chai Matcha','green','83']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-01T02:50:50.123Z"
    }
   },
   "outputs": [],
   "source": [
    "x = data[\"example\"]\n",
    "rec1 = get_top_n(x[0],x[2], newdf)\n",
    "bookrec= getBookrec(x[0])\n",
    "imgrec = imagelocs[bookrec]\n",
    "# Put the result in a nice dict so we can send it as json\n",
    "results = {\"tearec1\":rec1,\"tearec2\":rec2,\"tearec3\":rec3,\"bookrec\":bookrec, 'img':img}\n",
    "#return flask.jsonify(results)\n",
    "\n",
    "#--------- RUN WEB APP SERVER ------------#\n",
    "\n",
    "# Start the app server on port 80\n",
    "# (The default website port)\n",
    "#app.run(host='0.0.0.0')\n",
    "# app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-01T02:50:50.995Z"
    }
   },
   "outputs": [],
   "source": [
    "print(rec1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
